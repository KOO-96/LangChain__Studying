{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5081888",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "- 언어 모델을 활용하여 애플리케이션 개발을 돕는 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4378f",
   "metadata": {},
   "source": [
    "## LangChain 주기능\n",
    "\n",
    "- 문맥 인식\n",
    "    - 언어모델(LLM)과 소스(프롬프트, 예제, 응답의 근거)를 연동하여 사용자의 문맥을 정확하게 이해합니다.\n",
    "\n",
    "- 추론 능력\n",
    "    - 제공된 문맥에 기반해 어떤 대답을 할지, 또는 어떠한 액션을 보일지에 대한 추론이 가능합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d786282",
   "metadata": {},
   "source": [
    "### API KEY 발급\n",
    "\n",
    "- LangChain 프레임워크에서 LLM 모델을 사용하기 위해서는 openai의 API KEY를 발급받아야합니다. \n",
    "- [링크](https://platform.openai.com/account/api-keys)에 접속하여 **_Log in_** / **_Sign up_**\n",
    "- \"Create new secret key\" 버튼 클릭<br> \n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/KOO-96/LangChain__Studying/main/image/img1.png\" width=\"50%\" height=\"50%\">\n",
    "</p><br>  \n",
    "- Name 에는 발급하는 키에 대한 별칭을 입력하고 \"Create secret key\" 버튼 클릭<br> \n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/KOO-96/LangChain__Studying/main/image/img2.png\" width=\"40%\" height=\"50%\">\n",
    "</p><br> \n",
    "\n",
    "- 새롭게 발급한 키를 복사합니다. 잃어버리면 다시 발급받으셔야 합니다. 그리고 유출되지 않도록 안전한 곳에 저장해두셔야 합니다!<br> \n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/KOO-96/LangChain__Studying/main/image/img3.png\" width=\"40%\" height=\"50%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본격적으로 모듈 설치를 진행하겠습니다.\n",
    "\n",
    "# openai, langchain 파이썬 패키지 설치\n",
    "pip install openai langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccf573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '발급받은 OPENAI API KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db81df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 가능한 모델 리스트 확인이 가능합니다.\n",
    "import openai\n",
    "\n",
    "model_list = sorted([m['id'] for m in openai.Model.list()['data']])\n",
    "for m in model_list:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465d378",
   "metadata": {},
   "source": [
    "### ChatOpenAI\n",
    "\n",
    "- OpenAI 사의 채팅 전용 Large Language Model(llm)입니다.\n",
    "\n",
    "#### Option\n",
    "\n",
    "- temperature\n",
    "    - 0~2 사이의 값을 선택\n",
    "    - 높은 값은 출력 값을 더 랜덤하게 결정하고, 낮은 값은 집중된 값과 결정론적으로 출력합니다.\n",
    "    - 즉, 높은 값은 창의적인 답변, 낮은 값은 정확한 답변 출력을 시도합니다.\n",
    "    \n",
    "- max_tokens\n",
    "    - 채팅 완성에서 생성할 토큰의 최대 갯수\n",
    "    \n",
    "- model_name : 적용이 가능한 모델 리스트\n",
    "    - gpt-3.5-turbo\n",
    "    - gpt-3.5-turbo-0301\n",
    "    - gpt-3.5-turbo-0613\n",
    "    - gpt-3.5-turbo-16k\n",
    "    - gpt-3.5-turbo-16k-0613\n",
    "    - gpt-3.5-turbo-instruct\n",
    "    - gpt-3.5-turbo-instruct-0914\n",
    "    - gpt-4\n",
    "    - gpt-4-0314\n",
    "    - gpt-4-0613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \n",
    "                 max_tokens=2048,             # 최대 토큰수\n",
    "                 model_name='gpt-3.5-turbo',  # 모델명\n",
    "                )\n",
    "\n",
    "# 질의내용\n",
    "question = '대한민국의 수도는 뭐야?'\n",
    "\n",
    "# 질의\n",
    "print(f'[답변]: {llm.predict(question)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd9efb",
   "metadata": {},
   "source": [
    "### PromptTemplate\n",
    "\n",
    "- 사용자의 입력 값을 사용하여 완전한 프롬프트 문자열을 만드는데 사용하는 템플릿입니다.\n",
    "\n",
    "- Options\n",
    "    - template: 템플릿 문자열로 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.\n",
    "\n",
    "    - input_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의하고 사용되는 변수의 이름을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026cec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 질문 템플릿 형식 정의\n",
    "template = '{country}의 수도는 뭐야?'\n",
    "\n",
    "# input_variables -> 리스트 형식으로 변수 이름을 정의\n",
    "prompt = PromptTemplate(template=template, input_variables=['country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a2fb2",
   "metadata": {},
   "source": [
    "### LLMChain 객체\n",
    "\n",
    "- LLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다\n",
    "\n",
    "- Options\n",
    "    - prompt\n",
    "        - 위에서 지정한 PromptTemplate 객체를 의미합니다.\n",
    "    - llm\n",
    "        - 언어 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921012dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe40a9",
   "metadata": {},
   "source": [
    "1. run() : Prompt 실행   \n",
    "```\n",
    "print(llm_chain.run(country='일본'))\n",
    "> 일본의 수도는 도쿄입니다.\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "print(llm_chain.run(country='캐나다'))\n",
    "> 캐나다의 수도는 오타와(Ottawa)입니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d8434",
   "metadata": {},
   "source": [
    "2. apply() : 여러개의 입력을 한 번에 실행 \n",
    "\n",
    "```\n",
    "input_list = [\n",
    "    {'country': '호주'},\n",
    "    {'country': '중국'},\n",
    "    {'country': '네덜란드'}\n",
    "]\n",
    "\n",
    "llm_chain.apply(input_list)\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "> [{'text': '호주의 수도는 캔버라입니다.'},\n",
    " {'text': '중국의 수도는 베이징(北京)입니다.'},\n",
    " {'text': '네덜란드의 수도는 암스테르담(Amsterdam)입니다.'}]\n",
    "```\n",
    "리스트로 출력되는 부분을 반복문을 사용해서 결과를 확인해보겠습니다.\n",
    "```\n",
    "# input_list 에 대한 결과 반환\n",
    "result = llm_chain.apply(input_list)\n",
    "\n",
    "# 반복문으로 결과 출력\n",
    "for res in result:\n",
    "    print(res['text'].strip())\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "> 호주의 수도는 캔버라입니다.\n",
    "중국의 수도는 베이징(北京)입니다.\n",
    "네덜란드의 수도는 암스테르담(Amsterdam)입니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d181a54",
   "metadata": {},
   "source": [
    "3. generate() : 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사합니다. LLMResult 같은 경우 토큰 사용량과 종료 이유와 같은 유용한 생성 정보를 자주 포함하고 있습니다.\n",
    "\n",
    "```\n",
    "# input_list 에 대한 결과 반환\n",
    "generated_result = llm_chain.generate(input_list)\n",
    "print(generated_result)\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "> generations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34c4b9",
   "metadata": {},
   "source": [
    "```\n",
    "generated_result.generations\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))],\n",
    " [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))],\n",
    " [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f89d7",
   "metadata": {},
   "source": [
    "- 토큰 사용량 출력  \n",
    "```\n",
    "generated_result.llm_output\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "> {'token_usage': {'prompt_tokens': 58,\n",
    "  'completion_tokens': 57,\n",
    "  'total_tokens': 115},\n",
    " 'model_name': 'gpt-3.5-turbo'}\n",
    "```\n",
    "- run ID 출력   \n",
    "```\n",
    "generated_result.run\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "> [RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\n",
    " RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\n",
    " RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\n",
    "```\n",
    "\n",
    "- 최종 답변 출력\n",
    "\n",
    "```\n",
    "for gen in generated_result.generations:\n",
    "    print(gen[0].text.strip())\n",
    "    \n",
    "-----------------------------------\n",
    "\n",
    "> 호주의 수도는 캔버라입니다.\n",
    "중국의 수도는 베이징(北京)입니다.\n",
    "네덜란드의 수도는 암스테르담(Amsterdam)입니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d1a12",
   "metadata": {},
   "source": [
    "4. 2개 이상의 변수를 템플릿 안에 정의 : 2개 이상의 변수를 적용하여 템플릿을 생성이 가능합니다.  \n",
    "2개 이상의 변수(input_variables) 를 활용하여 템플릿 구성\n",
    "\n",
    "```\n",
    "# 질문 템플릿 형식 정의\n",
    "template = '{area1} 와 {area2} 의 시차는 몇시간이야?'\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\n",
    "\n",
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "print(llm_chain.run(area1='서울', area2='파리'))\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "> 서울과 파리의 시차는 8시간입니다. 서울이 파리보다 8시간 앞서 있습니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8297ec",
   "metadata": {},
   "source": [
    "5. 스트리밍(Streaming) : 질의에 대한 답변을 실시간으로 받을 때 유용한 기술입니다.\n",
    "\n",
    "- 아래와 같이 <span style=\"background-color:#fff5b1\">streaming = True</span>로 설정하고 StreamingStdOutCallbackHandler() 을 콜백으로 지정합니다.\n",
    "\n",
    "```\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \n",
    "                 max_tokens=2048,             # 최대 토큰수\n",
    "                 model_name='gpt-3.5-turbo',  # 모델명\n",
    "                 streaming=True,              \n",
    "                 callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                )\n",
    "                \n",
    "question = '호주의 수도가 어디였지?'\n",
    "\n",
    "response = llm.predict(question)\n",
    "response\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "> 호주의 수도는 캔버라입니다 \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe99c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
